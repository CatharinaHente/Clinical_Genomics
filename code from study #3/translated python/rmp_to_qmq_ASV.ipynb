{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Bio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SeqIO\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSeq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Seq\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSeqRecord\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SeqRecord\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Bio'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import random\n",
    "\n",
    "random.seed(531)\n",
    "\n",
    "# Load sequences from a file or database\n",
    "# Replace with actual loading function or path if data format differs\n",
    "LCPM_seq_filtered = \"LCPM_runs_589_seq_new_SLV_nr99_v138.1_filtered.fasta\"\n",
    "\n",
    "# Save the DNA sequences to a FASTA file\n",
    "def write_dna_sequences(seqs, filename):\n",
    "    records = [SeqRecord(Seq(seq), id=f\"seq{i+1}\", description=\"\") for i, seq in enumerate(seqs)]\n",
    "    SeqIO.write(records, filename, \"fasta\")\n",
    "\n",
    "# Uncomment to save the filtered sequences\n",
    "# write_dna_sequences(LCPM_seq_filtered, \"LCPM_runs_589_seq_new_SLV_nr99_v138.1_filtered.fa\")\n",
    "\n",
    "# Assume GCN predictions have been generated and loaded into a DataFrame `df_cnv`\n",
    "df_cnv = pd.read_csv(\"LCPM_runs_589_seq_new_SLV_nr99_v138.1_filtered_GCN.csv\")  # Example file path\n",
    "df_cnv.set_index('label', inplace=True)\n",
    "\n",
    "# Load the microbiome data as Phyl.Object.ASV (simulated data here for illustration)\n",
    "Phyl_Object_ASV = pd.read_csv(\"Phyl_Object_ASV.csv\", index_col=0)  # Example file path\n",
    "\n",
    "# Check for taxa not present in the CNV database\n",
    "taxa_in_data = set(Phyl_Object_ASV.columns)\n",
    "taxa_in_cnv = set(df_cnv.index)\n",
    "missing_taxa = taxa_in_data - taxa_in_cnv\n",
    "print(\"Taxa missing from CNV database:\", missing_taxa)\n",
    "\n",
    "# CNV correction\n",
    "otu_table = Phyl_Object_ASV.copy()\n",
    "otu_copy = otu_table.join(df_cnv[['x']], how='left')\n",
    "otu_copy.drop(columns=['label', 'probs'], inplace=True, errors='ignore')\n",
    "otu_cnv = otu_copy.div(otu_copy['x'], axis=0).drop(columns=['x'])\n",
    "\n",
    "# Prepare metadata\n",
    "metadata_QMP = pd.DataFrame(index=otu_table.index)  # Load sample data as needed\n",
    "\n",
    "# Rarefying function for even sampling depth\n",
    "def rarefy_even_sampling_depth_opt(cnv_corrected_abundance_table, cell_counts_table, minimum_nr_reads):\n",
    "    assert sorted(cnv_corrected_abundance_table.index) == sorted(cell_counts_table.index), \\\n",
    "        \"cnv_corrected_abundance_table and cell_counts_table do not have the same sample names.\"\n",
    "\n",
    "    cnv_corrected_abundance_table = np.ceil(cnv_corrected_abundance_table).astype(int)\n",
    "    cell_counts_table = cell_counts_table.loc[cnv_corrected_abundance_table.index].T\n",
    "\n",
    "    sample_sizes = cnv_corrected_abundance_table.sum(axis=1)\n",
    "    sampling_depths = sample_sizes / cell_counts_table.iloc[0]\n",
    "    minimum_sampling_depth = sampling_depths.min()\n",
    "\n",
    "    rarefy_to = cell_counts_table.iloc[0] * minimum_sampling_depth\n",
    "    if all(rarefy_to > minimum_nr_reads):\n",
    "        samples_to_exclude = []\n",
    "        minimum_sampling_depth_opt = minimum_sampling_depth\n",
    "    else:\n",
    "        lost_after_rarefaction = []\n",
    "        for i in range(len(sampling_depths)):\n",
    "            min_depth = sorted(sampling_depths, reverse=True)[len(sampling_depths) - i - 1]\n",
    "            rarefy_to = cell_counts_table.iloc[0] * min_depth\n",
    "            lost_after_rarefaction.append((rarefy_to < minimum_nr_reads).sum())\n",
    "        lost_in_total = [lost_after_rarefaction[i] + i for i in range(len(lost_after_rarefaction))]\n",
    "        nr_samples_to_exclude = np.argmin(lost_in_total)\n",
    "        minimum_sampling_depth_opt = sorted(sampling_depths, reverse=True)[len(sampling_depths) - nr_samples_to_exclude - 1]\n",
    "        samples_to_exclude = sampling_depths[sampling_depths < minimum_sampling_depth_opt].index.tolist()\n",
    "\n",
    "    rarefy_to_opt = np.round(cell_counts_table.iloc[0] * minimum_sampling_depth_opt).astype(int)\n",
    "\n",
    "    rarefied_matrix = []\n",
    "    samples_included = []\n",
    "    for i, row in cnv_corrected_abundance_table.iterrows():\n",
    "        if i not in samples_to_exclude and rarefy_to_opt[i] > minimum_nr_reads:\n",
    "            print(f\"Sample {i} rarefied to {rarefy_to_opt[i]} reads.\")\n",
    "            rarefied_sample = np.random.choice(row.index, size=rarefy_to_opt[i], replace=False, p=row / row.sum())\n",
    "            rarefied_matrix.append(pd.Series(rarefied_sample).value_counts())\n",
    "            samples_included.append(i)\n",
    "\n",
    "    print(\"Optimal sampling depth:\", minimum_sampling_depth_opt)\n",
    "    print(f\"{len(samples_to_exclude)} samples excluded due to exclusion:\", samples_to_exclude)\n",
    "\n",
    "    rarefied_matrix_df = pd.DataFrame(rarefied_matrix).fillna(0)\n",
    "    normalised_rarefied_matrix = rarefied_matrix_df.div(rarefied_matrix_df.sum(axis=1), axis=0)\n",
    "    QMP = normalised_rarefied_matrix.multiply(cell_counts_table.iloc[0][samples_included], axis=0)\n",
    "    return QMP\n",
    "\n",
    "# Define necessary inputs for rarefaction\n",
    "cnv_corrected_abundance_table = otu_cnv.T\n",
    "cell_counts_table = metadata_QMP[['Cell_counts']]\n",
    "minimum_nr_reads = 500 / otu_copy['x'].mean()\n",
    "\n",
    "QMP = rarefy_even_sampling_depth_opt(cnv_corrected_abundance_table, cell_counts_table, minimum_nr_reads)\n",
    "\n",
    "# Create a phyloseq-like object (dictionary with DataFrames)\n",
    "QMP_ASV_LCPM_SLV = {\n",
    "    'otu_table': QMP,\n",
    "    'sample_data': metadata_QMP,\n",
    "    'tax_table': Phyl_Object_ASV.columns,  # Modify as necessary\n",
    "    'refseq': LCPM_seq_filtered  # Placeholder for DNA sequences\n",
    "}\n",
    "\n",
    "# Save QMP_ASV_LCPM_SLV as needed\n",
    "# QMP_ASV_LCPM_SLV.to_pickle(\"QMP_ASV_LCPM_SLV.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
